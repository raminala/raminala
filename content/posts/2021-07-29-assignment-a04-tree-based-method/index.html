---
title: 'Assignment A04: Tree based Method'
author: Ramin Ala
date: '2021-07-29'
slug: []
categories: []
tags:
  - Assignment
  - Tree-Based Models
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p><strong><em>Ramin Ala</em></strong></p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Random decision forests correct for decision treesâ€™ habit of overfitting to their training set.</p>
<p>Random Forest algorithm is a special type of bagging applied to decision trees.</p>
<p>the random forest provides a strong improvement, which consists of applying bagging to the data and bootstrap sampling to the predictor variables at each split. This means that at each splitting step of the tree algorithm, a random sample of n predictors is chosen as split candidates from the full set of the predictors.</p>
</div>
<div id="libraries" class="section level2">
<h2>libraries</h2>
<pre class="r"><code>library(tidyverse)
library(tidymodels)

library(caret)
library(randomForest)</code></pre>
</div>
<div id="splitting-data" class="section level2">
<h2>Splitting data</h2>
<p>Splitting the data to training (80%) and test set (20%)</p>
<pre class="r"><code>set.seed(20)

# Split 80% of data as training set
training_bank &lt;- bank$subscription_status %&gt;% 
  createDataPartition(p = 0.8, list = FALSE)

train.data  &lt;- bank[training_bank, ]
test.data &lt;- bank[-training_bank, ]</code></pre>
</div>
<div id="computing-random-forest-classifier" class="section level2">
<h2>Computing random forest classifier</h2>
<pre class="r"><code>set.seed(20)

# Fit the model on the training set
model &lt;- train(
  factor(subscription_status) ~., data = train.data, method = &quot;rf&quot;,
  trControl = trainControl(&quot;cv&quot;, number = 10),
  importance = TRUE
  )

# Best tuning parameter
model$bestTune</code></pre>
<pre><code>##   mtry
## 1    2</code></pre>
</div>
