---
title: Regression Model Validation- Cross-Validation
author: ''
date: '2021-07-21'
slug: []
categories: []
tags:
  - Regression
  - Classification
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --</code></pre>
<pre><code>## v ggplot2 3.3.3     v purrr   0.3.4
## v tibble  3.1.1     v dplyr   1.0.6
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.1</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<pre class="r"><code># Load the data
data(&quot;swiss&quot;)
# Inspect the data
sample_n(swiss, 3)</code></pre>
<pre><code>##              Fertility Agriculture Examination Education Catholic
## V. De Geneve      35.0         1.2          37        53    42.34
## Neuveville        76.9        43.5          17        15     5.16
## Grandson          71.7        34.0          17         8     3.30
##              Infant.Mortality
## V. De Geneve             18.0
## Neuveville               20.6
## Grandson                 20.0</code></pre>
<div id="spliting-dataset" class="section level2">
<h2>Spliting dataset</h2>
<p>splits the swiss data set so that 80% is used for training a linear regression model and 20% is used to evaluate the model performance.</p>
<pre class="r"><code># Split the data into training and test set

set.seed(10242)

training.samples &lt;- swiss$Fertility %&gt;%
  createDataPartition(p = 0.8, list = FALSE)

train.data  &lt;- swiss[training.samples, ]

test.data &lt;- swiss[-training.samples, ]

# Build the model
model &lt;- lm(Fertility ~., data = train.data)

# Make predictions and compute the R2, RMSE and MAE
predictions &lt;- model %&gt;% predict(test.data)

data.frame( R2 = R2(predictions, test.data$Fertility),
            RMSE = RMSE(predictions, test.data$Fertility),
            MAE = MAE(predictions, test.data$Fertility))</code></pre>
<pre><code>##          R2    RMSE      MAE
## 1 0.5918168 7.09516 5.673755</code></pre>
<p>When comparing two models, the one that produces the <em>lowest test sample RMSE</em> is the <em>preferred model</em>.</p>
</div>
<div id="rmse" class="section level2">
<h2>RMSE</h2>
<p>the RMSE and the MAE are measured in the same scale as the outcome variable. Dividing the RMSE by the average value of the outcome variable will give you the prediction error rate, which should be as small as possible.</p>
<pre class="r"><code>RMSE(predictions, test.data$Fertility)/mean(test.data$Fertility)</code></pre>
<pre><code>## [1] 0.09813499</code></pre>
</div>
