---
title: assignment-03--
author: ''
date: '2021-07-24'
slug: []
categories: []
tags: []
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div id="resampling" class="section level2">
<h2>Resampling</h2>
<pre class="r"><code>library(caret)

library(yardstick)

library(tictoc)</code></pre>
</div>
<div id="resampling-methods" class="section level2">
<h2>Resampling methods</h2>
</div>
<div id="cross-validation-methods" class="section level2">
<h2><strong><em>Cross-Validation methods</em></strong></h2>
</div>
<div id="loocv-leave-one-out-cross-validation" class="section level2">
<h2>LOOCV (Leave one out cross validation)</h2>
<p>For this dataset, the LOOCV method takes long time to process. Because it consists building the model for (4521-1) times and evaluating the remaining sample with the model and averaging errors after finishinf process.</p>
<p>We are using tictoc library to measure the run time for each code chunk to evaluate the performance of these methods in terms of run time.</p>
<hr />
<pre class="r"><code>start_time_LOOCV &lt;- Sys.time()


# Define training control
train.control_LOOCV &lt;- trainControl(method = &quot;LOOCV&quot;)

# Train the model
model_LOOCV &lt;- train(subscription_status ~ ., data = bank, method = &quot;lm&quot;,
               trControl = train.control_LOOCV)
# Summarize the results
print(model_LOOCV)</code></pre>
<pre><code>## Linear Regression 
## 
## 4521 samples
##    9 predictor
## 
## No pre-processing
## Resampling: Leave-One-Out Cross-Validation 
## Summary of sample sizes: 4520, 4520, 4520, 4520, 4520, 4520, ... 
## Resampling results:
## 
##   RMSE          Rsquared  MAE         
##   8.053605e-16  1         4.179036e-16
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<pre class="r"><code>end_time_LOOCV &lt;- Sys.time()

LOOCV_run_time= end_time_LOOCV - start_time_LOOCV

#Print run time
print(LOOCV_run_time)</code></pre>
<pre><code>## Time difference of 1.284482 mins</code></pre>
<p>Calculated errors shows there is negligible error in predicting outputs. we will see this in final section called confusion matrix. Besides, running of this method lasted “1.23 min”.</p>
</div>
<div id="k-fold-cross-validation" class="section level2">
<h2>K-fold cross-validation</h2>
<p>Here k selected as 10 (by setting number argument to 10 in trainControl function). This number selected because there are 4521 observation in dataset.</p>
<pre class="r"><code># Define training control
set.seed(120) 

start_time_K_fold &lt;- Sys.time()

train.control_K_fold &lt;- trainControl(method = &quot;repeatedcv&quot;, number = 10, repeats = 4)

# Train the model
model_K_fold &lt;- train(subscription_status ~., data = bank, method = &quot;lm&quot;,
               trControl = train.control_K_fold)
# Summarize the results
print(model_K_fold)</code></pre>
<pre><code>## Linear Regression 
## 
## 4521 samples
##    9 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 4 times) 
## Summary of sample sizes: 4069, 4069, 4069, 4069, 4069, 4069, ... 
## Resampling results:
## 
##   RMSE          Rsquared  MAE         
##   6.116485e-16  1         3.847581e-16
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<pre class="r"><code>end_time_K_fold &lt;- Sys.time()

K_fold_run_time= end_time_K_fold - start_time_K_fold

#Print run time
print(K_fold_run_time)</code></pre>
<pre><code>## Time difference of 1.213336 secs</code></pre>
<p>Again error is nearly zero but code run in just 1.4 seconds that is a great improvement in caparison with LOOCV method.</p>
</div>
<div id="bootstrap-method" class="section level2">
<h2>Bootstrap method</h2>
<pre class="r"><code># Define training control

start_time_bootstrap &lt;- Sys.time()

train.control_Bootstrap &lt;- trainControl(method = &quot;boot&quot;, number = 100)

# Train the model
model_Bootstrap &lt;- train(subscription_status ~., data = bank, method = &quot;lm&quot;,
               trControl = train.control_Bootstrap)
# Summarize the results
print(model_Bootstrap)</code></pre>
<pre><code>## Linear Regression 
## 
## 4521 samples
##    9 predictor
## 
## No pre-processing
## Resampling: Bootstrapped (100 reps) 
## Summary of sample sizes: 4521, 4521, 4521, 4521, 4521, 4521, ... 
## Resampling results:
## 
##   RMSE          Rsquared  MAE         
##   1.030247e-15  1         6.465142e-16
## 
## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE</code></pre>
<pre class="r"><code>end_time_bootstrap &lt;- Sys.time()

bootstrap_run_time= end_time_bootstrap - start_time_bootstrap

#Print run time
print(bootstrap_run_time)</code></pre>
<pre><code>## Time difference of 3.569924 secs</code></pre>
<p>Error is also negligible here, and code run in just 3.6 seconds that is a great improvement in caparison with LOOCV method but slower than K-fold. Obviously, number of iteration affects timing.</p>
</div>
<div id="evaluating-performance-with-confusion-matrix" class="section level2">
<h2>Evaluating performance with confusion matrix</h2>
<p>Calculating performance metrics with the yardstick package provides insight into how well a classification model is performing on the test dataset.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Confusion matrices and heatmap plots shows there are no error in predictions.</p>
<p>Explanations about predictions of SLR (Single linear regression) and MLR (Multiple linear regression) is necessary. In these cases, we defined a threshold of probabilities that separates “yes” and “no” outcomes. These thresholds are selected so that number of errors (numbers in sub diagonal of matrix) become minimum.</p>
</div>
