---
title: 'Final Project: Business Analytics'
author: ''
date: '2021-08-01'
slug: final-project-business-analytics
categories:
  - Basics
  - ggplot2
  - tidymodels
  - Tidyverse
tags:
  - Classification
  - data_visualization
  - data_wrangling
---

## Assessing the financial benefit of the project

This project would benefit credit card providers by detecting customers who have the potential of missing their credit card payments. Although this is not an unfamiliar situation for these institutions, it affects their revenue every year by making them prosecute these clients. This project gives you two options to avoid these customers based on two categories of information you already have!

First, a short explanation about the method we used to assess the reliability of our model. This model has been tested by a population of more than 20'000 applicants. Please note that this population is new to our model. In other words, our model has not any bias about them. 

The first piece of information for making a decision is demographic information. This is what you are collecting from a potential client when they are applying for a new credit card. Our model shows that by this information alone, you could detect 25% of those who would miss a payment. However, you will lose 15% of your good customers. In other words, we predict 25% of bad customers, but our model predicts 15% of your good clients as bad clients. Considering the huge financial burden of a bad client on the institute, losing those clients is sensible.

The second piece of information is credit bureau data. Using this information, our model would detect more bad clients, while it has a lower error rate. Providing numerical value, You will detect 50% of bad clients and will lose 25% of good customers.

Please note provided percents could later be modified by a limited modification in the model. For example, when you need to attract new customers, model could accept more customers with expense of accepting more bad clients and vise versa.


## Libraries

```{r}
library(tidymodels)
library(tidyverse)
library(Information)
library(ROSE)
library(e1071)
library(kernlab)
library(tidyverse)
library(caret)
library(ROCit)
library(brglm)
library(yardstick)
library(ggplot2)
```


## import two dataset and rename variables

For the convenience of data analysis, we have renamed the variables from the original dataset, after importing the there are as below:


```{r, echo=FALSE, message=FALSE, warning=FALSE}


bureau <- read_csv("Credit_Bureau.csv") %>%
  janitor::clean_names() %>%
rename(
    id= application_id,
    auto_loan= presence_of_open_auto_loan ,
    home_loan= presence_of_open_home_loan,
    trades_6m= no_of_trades_opened_in_last_6_months,
    inquiries_6m = no_of_inquiries_in_last_6_months_excluding_home_auto_loans,
    inquiries_12m= no_of_inquiries_in_last_12_months_excluding_home_auto_loans,
    utilization_12m =avgas_cc_utilization_in_last_12_months,
    trades_opened_12m =no_of_trades_opened_in_last_12_months,
    pl_trades_12m=no_of_pl_trades_opened_in_last_12_months,
    pl_trades_6m=no_of_pl_trades_opened_in_last_6_months,
   dpd_60_6m =  no_of_times_60_dpd_or_worse_in_last_6_months,
   dpd_90_12m =  no_of_times_90_dpd_or_worse_in_last_12_months,
   dpd_30_12m =  no_of_times_30_dpd_or_worse_in_last_12_months,
   dpd_90_6m =  no_of_times_90_dpd_or_worse_in_last_6_months,
   dpd_30_6m =  no_of_times_30_dpd_or_worse_in_last_6_months,
   dpd_60_12m =  no_of_times_60_dpd_or_worse_in_last_12_months
    )
    


demogs<- read_csv("demogs.csv") %>%
  janitor::clean_names() %>%
rename(
    id= application_id,
    marital= marital_status_at_the_time_of_application,
    dependents= no_of_dependents,
    residence=type_of_residence,
    company_months =no_of_months_in_current_company,
    residence_months =no_of_months_in_current_residence
    )

names(bureau)
names(demogs)

```

## bind two dataset, reordering columns (outcome: master dataset)

Here two datasets of demographic and credit bureau data are combined. besides, We ordered the column names and saved the dataset named as master here.


```{r, echo=FALSE, message=FALSE, warning=FALSE}

master <-  left_join(demogs, bureau, 'id') %>%
  subset(select = -performance_tag.y) %>%
  rename(performance_tag=performance_tag.x) 

master <- master[, 
                       c("id", "age", "gender", "marital", "dependents", "income",
               "education", "profession", "residence", "residence_months", "company_months", "dpd_90_6m",
               "dpd_60_6m", "dpd_30_6m", "dpd_90_12m", "dpd_60_12m", "dpd_30_12m", "utilization_12m",
               "trades_6m", "trades_opened_12m", "pl_trades_6m", "pl_trades_12m", "inquiries_6m", "inquiries_12m",
               "home_loan", "outstanding_balance", "total_no_of_trades",  "auto_loan",
               "performance_tag"
               )
                       ]
  
```



## weight of evidence (WOE) (and, equivalently, information value analysis)

As we know, weight of evidence and information value helps to explore data and screen variables and hence it will be easier for us to use those values as a benchmark to screen variables in relation to the dependent variable.Before calculating those values we need to prepare our data first.


***Data Preparation***

Fist of all we have omitted the missing values from the dataset as there is a lots of 'na' values exists and then we have removed the variable with customer ID.


```{r, echo=FALSE, message=FALSE, warning=FALSE}

#summary(bureau)
#master$age <- factor(master$age)

master_IV <- master %>%

na.omit(master) %>%
subset(select=-id)

#IV_Value = data.frame(IV$Summary)

#print(IV_Value)

```


***Compute Information Value and WOE***

As we know, for calculating WOE and IV value there several steps involved. In our data set there are both continuous and categorical variables, so first we need to split data into 10 parts and then calculate the number of events and non-events in each group (bin) and then the % of events and % of non-events in each group.Finally by taking natural log of division of % of non-events and % of events IV value is Calculated using the relevant functions. 


```{r, echo=FALSE, message=FALSE, warning=FALSE}
IV <- create_infotables(data=master_IV, y="performance_tag", bins=10, parallel=FALSE)
```

***Plot variables interms of WOE and IV values***

To visualize all the variables in terms of WOE and IV values here we plotted the variables below:


```{r, echo=FALSE, message=FALSE, warning=FALSE}
plot_infotables(IV, IV$Summary$Variable[1:27], same_scale=FALSE)

plot_infotables(IV, "inquiries_12m")
plot_infotables(IV, "age")

```



***Replace variables' values by the corresponding WOE value***

```{r, echo=FALSE, message=FALSE, warning=FALSE}

woe_data <- master %>%
  mutate( age = replace(age, between(age,-3,30),  -0.039506890)) %>%
  mutate( age = replace(age, between(age,31,35),   0.046882216)) %>%
  mutate( age = replace(age, between(age,36,38),   0.066531127)) %>%
  mutate( age = replace(age, between(age,39,41),   0.075316247)) %>%
  mutate( age = replace(age, between(age,42,44),  -0.061320756)) %>%
  mutate( age = replace(age, between(age,45,47),  -0.004329305)) %>%
  mutate( age = replace(age, between(age,48,50),  -0.007207997)) %>%
  mutate( age = replace(age, between(age,51,53),  -0.137458080)) %>%
  mutate( age = replace(age, between(age,54,57),   0.044718393)) %>%
  mutate( age = replace(age, between(age,58,65),  -0.013404982)) %>%
  
  mutate( gender = replace(gender, gender=="F",  0.028254108)) %>%
  mutate( gender = replace(gender, gender=="M",  -0.008890893)) %>%
  
  mutate( marital = replace(marital, marital=="Married",  -0.004058593)) %>%
  mutate( marital = replace(marital, marital=="Single",  0.023087052)) %>% 
  
  mutate( dependents = replace(dependents, dependents==1,  0.047511301)) %>%
  mutate( dependents = replace(dependents, dependents==2, -0.089738973)) %>% 
  mutate( dependents = replace(dependents, dependents==3,  0.051725860)) %>%
  mutate( dependents = replace(dependents, dependents==4, -0.029168607)) %>% 
  mutate( dependents = replace(dependents, dependents==5,  0.006997003)) %>%
  
  mutate( income = replace(income, between(income,-0.5,5),  0.299553096)) %>%
  mutate( income = replace(income, between(income,6,10),    0.270245403)) %>%
  mutate( income = replace(income, between(income,11,16),   0.074864917)) %>%
  mutate( income = replace(income, between(income,17,21),   0.089160195)) %>%
  mutate( income = replace(income, between(income,22,26),   0.007652167)) %>%
  mutate( income = replace(income, between(income,27,31),   0.071544388)) %>%
  mutate( income = replace(income, between(income,32,36),  -0.138694556)) %>%
  mutate( income = replace(income, between(income,37,41),  -0.264723534)) %>%
  mutate( income = replace(income, between(income,42,48),   -0.175401898)) %>%
  mutate( income = replace(income, between(income,49,60),  -0.363216455)) %>%

  mutate( education = replace(education, education=="Bachelor",  0.0203476113)) %>%
  mutate( education = replace(education, education=="Masters",  -0.0008907703)) %>%
  mutate( education = replace(education, education=="Others",  0.5394285801)) %>%
  mutate( education = replace(education, education=="Phd",  -0.0085173636)) %>%
  mutate( education = replace(education, education=="Professional",  -0.0155472553)) %>%
  
  mutate( profession = replace(profession, profession=="SAL",  -0.02719623)) %>%
  mutate( profession = replace(profession, profession=="SE",  0.09099464)) %>%
  mutate( profession = replace(profession, profession=="SE_PROF",  -0.01586440)) %>% 
  
  mutate( residence = replace(residence, residence=="Company provided",  0.066903551)) %>%
  mutate( residence = replace(residence, residence=="Living with Parents",  0.074093102)) %>%
  mutate( residence = replace(residence, residence=="Others",  -0.514160027)) %>%
  mutate( residence = replace(residence, residence=="Owned",  -0.003167738	)) %>%
  mutate( residence = replace(residence, residence=="Rented",  -0.002327681)) %>%
  
  mutate( residence_months = replace(residence_months, between(residence_months,6,9),  -0.27504521)) %>%
  mutate( residence_months = replace(residence_months, between(residence_months,10,28),  0.50219013)) %>%
  mutate( residence_months = replace(residence_months, between(residence_months,29,49),  0.30145219)) %>%
  mutate( residence_months = replace(residence_months, between(residence_months,50,72),  0.14236553)) %>%
  mutate( residence_months = replace(residence_months, between(residence_months,73,97),  0.13184356)) %>%
  mutate( residence_months = replace(residence_months, between(residence_months,98,126),  -0.07614037)) %>%

  mutate( company_months = replace(company_months, between(company_months,3,5),  0.10380388)) %>%
  mutate( company_months = replace(company_months, between(company_months,6,12),  0.17693458)) %>%
  mutate( company_months = replace(company_months, between(company_months,13,19),  0.20495867)) %>%
  mutate( company_months = replace(company_months, between(company_months,20,26),  0.03865713)) %>%
  mutate( company_months = replace(company_months, between(company_months,27,33),  -0.08128390)) %>%
  mutate( company_months = replace(company_months, between(company_months,34,40),  0.01916403)) %>%
  mutate( company_months = replace(company_months, between(company_months,41,47),  -0.15950171)) %>%
  mutate( company_months = replace(company_months, between(company_months,48,53),  -0.22066994)) %>%
  mutate( company_months = replace(company_months, between(company_months,54,61),  -0.23006158)) %>%
  mutate( company_months = replace(company_months, between(company_months,62,133),  0.06500409)) %>%

  mutate( dpd_90_6m = replace(dpd_90_6m, dpd_90_6m==0,  -0.2664307)) %>%
  mutate( dpd_90_6m = replace(dpd_90_6m, between(dpd_90_6m,1,3), 0.6239753))  %>%
  
  mutate( dpd_60_6m = replace(dpd_60_6m, dpd_60_6m==0,  -0.3435695)) %>%
  mutate( dpd_60_6m = replace(dpd_60_6m, between(dpd_60_6m,1,5),  0.6230040))  %>%
  
  mutate( dpd_30_6m = replace(dpd_30_6m, dpd_30_6m==0,  -0.3958799)) %>%
  mutate( dpd_30_6m = replace(dpd_30_6m, dpd_30_6m==1,  0.4694610))  %>%
  mutate( dpd_30_6m = replace(dpd_30_6m, between(dpd_30_6m,2,7),  0.7403884)) %>%

  mutate( dpd_90_12m = replace(dpd_90_12m, dpd_90_12m==0,  -0.3647314)) %>%
  mutate( dpd_90_12m = replace(dpd_90_12m, dpd_90_12m==1,  0.5101573))  %>%
  mutate( dpd_90_12m = replace(dpd_90_12m, between(dpd_90_12m,2,5),  0.7218272)) %>%

  mutate( dpd_60_12m = replace(dpd_60_12m, dpd_60_12m==0,  -0.3591009)) %>%
  mutate( dpd_60_12m = replace(dpd_60_12m, dpd_60_12m==1,  0.2152035))  %>%
  mutate( dpd_60_12m = replace(dpd_60_12m, between(dpd_60_12m,2,7),  0.6939493)) %>%
  
  mutate( dpd_30_12m = replace(dpd_30_12m, dpd_30_12m==0,  -0.3853646)) %>%
  mutate( dpd_30_12m = replace(dpd_30_12m, between(dpd_30_12m,1,2),  0.2848629))  %>%
  mutate( dpd_30_12m = replace(dpd_30_12m, between(dpd_30_12m,3,9),  0.7965947))   %>%
  
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,0,4),  -0.79974940)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,5,6),  -0.79817351)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,7,8),  -0.79187508)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,9,11),  -0.66998411)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,12,14),  -0.46603868)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,15,21),  -0.07600819)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,22,37),  0.47376425)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,38,51),  0.58503960)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,52,71),  0.56644494)) %>%
  mutate( utilization_12m = replace(utilization_12m, between(utilization_12m,72,113),  0.38568829)) %>%
  
  mutate( trades_6m = replace(trades_6m, trades_6m==0,  -0.7402284	)) %>%
  mutate( trades_6m = replace(trades_6m, trades_6m==1,  -0.4760898	)) %>%
  mutate( trades_6m = replace(trades_6m, trades_6m==2,  0.2364562)) %>%
  mutate( trades_6m = replace(trades_6m, trades_6m==3,  0.4327520)) %>%
  mutate( trades_6m = replace(trades_6m, trades_6m==4,  0.5215066)) %>%
  mutate( trades_6m = replace(trades_6m, between(trades_6m,5,12),  0.1335172))%>%
  
  mutate( trades_opened_12m = replace(trades_opened_12m, trades_opened_12m==0,  -0.894500098)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, trades_opened_12m==1,  -1.016850939)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, trades_opened_12m==2,  -0.813563496)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, between(trades_opened_12m,3,4),  0.011943065)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, trades_opened_12m==5,  0.207396853)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, between(trades_opened_12m,6,7),  0.448049021)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, between(trades_opened_12m,8,9),  0.573136724)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, between(trades_opened_12m,10,12),  0.485011064)) %>%
  mutate( trades_opened_12m = replace(trades_opened_12m, between(trades_opened_12m,13,28),  0.002793356)) %>%
  
  mutate( pl_trades_6m = replace(pl_trades_6m, pl_trades_6m==0,  -0.6768231)) %>%
  mutate( pl_trades_6m = replace(pl_trades_6m, pl_trades_6m==1,  0.2013560)) %>%
  mutate( pl_trades_6m = replace(pl_trades_6m, pl_trades_6m==2,  0.4397232)) %>%
  mutate( pl_trades_6m = replace(pl_trades_6m, between(pl_trades_6m,3,6),  0.3576285))%>%
  
  mutate( pl_trades_12m = replace(pl_trades_12m, pl_trades_12m==0,  -0.9471609	)) %>%
  mutate( pl_trades_12m = replace(pl_trades_12m, pl_trades_12m==1,  -0.1279522	)) %>%
  mutate( pl_trades_12m = replace(pl_trades_12m, pl_trades_12m==2,  0.2522636)) %>%
  mutate( pl_trades_12m = replace(pl_trades_12m, pl_trades_12m==3,  0.4161652)) %>%
  mutate( pl_trades_12m = replace(pl_trades_12m, pl_trades_12m==4,  0.5016385)) %>%
  mutate( pl_trades_12m = replace(pl_trades_12m, pl_trades_12m==5,  0.4196919)) %>%
  mutate( pl_trades_12m = replace(pl_trades_12m, between(pl_trades_12m,6,12),  0.2376102))%>%

  mutate( inquiries_6m = replace(inquiries_6m, inquiries_6m==0,  -0.75470945)) %>%
  mutate( inquiries_6m = replace(inquiries_6m, inquiries_6m==1,  0.18011102)) %>%
  mutate( inquiries_6m = replace(inquiries_6m, inquiries_6m==2,  0.21415526)) %>%
  mutate( inquiries_6m = replace(inquiries_6m, between(inquiries_6m,3,4),  0.50749871)) %>%
  mutate( inquiries_6m = replace(inquiries_6m, between(inquiries_6m,5,10),  0.01163274)) %>%
  
  mutate( inquiries_12m = replace(inquiries_12m, inquiries_12m==0,  -1.14210740)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, inquiries_12m==1,  -0.02178118)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, inquiries_12m==2,   0.14294109)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, inquiries_12m==3,   0.16773844)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, inquiries_12m==4,   0.25020441)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, inquiries_12m==5,   0.57635386)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, between(inquiries_12m,6,8),  0.48580800)) %>%
  mutate( inquiries_12m = replace(inquiries_12m, between(inquiries_12m,9,20),  0.01255320))  %>%
  
  mutate( home_loan = replace(home_loan, home_loan==0,  0.07322469)) %>%
  mutate( home_loan = replace(home_loan, home_loan==1, -0.23694925))%>%
  
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,0,7786),  -0.9764093)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,7787,55454),  -0.8487953)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,56065,392876),  -0.0769904)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,392909,590337),   0.2715642)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,590343,777938),   0.4655003)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,777956,976179),   0.4142887)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,976183,1362849),   0.3866071)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,1362864,2962106),  -0.3887941)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,2962114,3289876),  -0.8015947)) %>%
  mutate( outstanding_balance = replace(outstanding_balance, between(outstanding_balance,3289931,5218801),   0.2963591)) %>%


  mutate( total_no_of_trades = replace(total_no_of_trades, total_no_of_trades==1,  -1.05653995)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, total_no_of_trades==2,   -1.01505568	)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, total_no_of_trades==3,   -0.69881486)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, total_no_of_trades==4,  -0.44466272)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, total_no_of_trades==5,  -0.04461396)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, between(total_no_of_trades,6,7),  0.21585574)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, total_no_of_trades==8,   0.46328513)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, between(total_no_of_trades,9,10),  0.54093915)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, between(total_no_of_trades,11,19),  0.42543258)) %>%
  mutate( total_no_of_trades = replace(total_no_of_trades, between(total_no_of_trades,20,44),  -0.06846777	)) %>%
  
  mutate( auto_loan = replace(auto_loan, auto_loan==0,  0.01191341	)) %>%
  mutate( auto_loan = replace(auto_loan, auto_loan==1,   -0.13519714	))



  #print(IV$Tables$dpd_60_6m, row.names=FALSE)
  #names(woe_data)
  
 # write.csv(woe_data,"C:\\Fundamentals of Analytics\\woe_data.csv", row.names = FALSE)
```


## Univariate Analysis of Master data 

According to the IV analysis results of the important variable we have selected the most important variables from the master data set for further analysis. As we know, the IV value 0.3 to 0.5, then the predictor has a strong relationship to the Goods or Bad odds ratio.For exploring the data set some basic univariate Analysis on Master data is done below first. This analysis will answer the questions below:
1.What patterns No of trades in last 12 months follows?
2. What distribution inquiries 12 months have on the data?
3. Does outstanding balance have any affect on performance tag?
4. How are the summary of Number of pl Trades Opened and Number Trades Opened in last 12 months?


***Summary of inquiries_12m***


```{r, echo=FALSE, message=FALSE, warning=FALSE}


master %>%
    summarize(variable = "inquiries_12m", mean_inquiries_12m = mean(inquiries_12m), st_dev_cty = sd(inquiries_12m)) 

master %>%
    summarize(variable = "inquiries_12m",
              q0.2 = quantile(inquiries_12m, 0.2),
              q0.4 = quantile(inquiries_12m, 0.4),
              q0.6 = quantile(inquiries_12m, 0.6),
              q0.8 = quantile(inquiries_12m, 0.8)) 

ggplot(master, aes(x = inquiries_12m)) +
  geom_histogram(binwidth = 1.25, color = "black",fill = "skyblue") +
  labs(
    x = "Number of inquiries made in last 12m",
    y = "Frequency",
    title = "Summary of Number of inquiries in last 12m")
```

The average number of inquiries in last 12 months excluding home and auto loans is 3.5.Most of the cases the number of inquiries is zero and the maximum number of inquiries has made is almost 20.


***outstanding_balance***

```{r, echo=FALSE, message=FALSE, warning=FALSE}

na.omit(master$outstanding_balance) %>%
  summary(master$outstanding_balance)

balance_except_zero <- master[master$outstanding_balance > 0, ] 

ggplot(balance_except_zero, aes(outstanding_balance, fill = performance_tag)) + 
    geom_histogram(data = subset(balance_except_zero,performance_tag==1),fill="red",alpha=.5) + 
    geom_histogram(data = subset(balance_except_zero,performance_tag==0),fill="blue",alpha=.2) + 
    ggtitle("Performance Tag by outstanding_balance")


```

The mean value of outstanding_balance is 1249092. And we see that the outstanding_balance are divided in to two clusters, bad performance is relatively higher for lower outstanding_balance than higher outstanding balance. We see that there are some effects of outstanding balance on performance tag.


***pl_trades_12m***

```{r, echo=FALSE, message=FALSE, warning=FALSE}

master %>%
    summarize(variable = "pl_trades_12m", mean_pl_trades_12m = mean(pl_trades_12m), st_dev_pl_trades_12m = sd(pl_trades_12m))

master %>%
    summarize(variable = "pl_trades_12m",
              q0.2 = quantile(pl_trades_12m, 0.2),
              q0.4 = quantile(pl_trades_12m, 0.4),
              q0.6 = quantile(pl_trades_12m, 0.6),
              q0.8 = quantile(pl_trades_12m, 0.8)) 

ggplot(master, aes(x = pl_trades_12m)) +
  geom_histogram(binwidth = 1.25, color = "black",fill = "skyblue") +
  labs(
    x = "Number of pl Trades Opened in last 12m",
    y = "Frequency",
    title = "Summary of Number of pl Trades Opened in last 12m")
```

The highest number of pl Trades Opened in last 12 months is 5, the average number of pl trades opened is 2.4 approximately.The highest frequency has occurred for zero or no trades in last 12 months.


***trades_opened_12m***

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(pander)
master %>%
    summarize(variable = "trades_opened_12m", mean_trades_opened_12m = mean(trades_opened_12m), st_dev_trades_opened_12m = sd(trades_opened_12m)) 

master %>%
    summarize(variable = "trades_opened_12m",
              q0.2 = quantile(trades_opened_12m, 0.2),
              q0.4 = quantile(trades_opened_12m, 0.4),
              q0.6 = quantile(trades_opened_12m, 0.6),
              q0.8 = quantile(trades_opened_12m, 0.8)) 
ggplot(master, aes(x = trades_opened_12m)) +
  geom_histogram(binwidth = 1.25, color = "black",fill = "skyblue") +
  labs(
    x = "Number of Trades Opened in last 12m",
    y = "Frequency",
    title = "Summary of Number of Trades Opened in last 12m")
```

The average number of trades opened is 5.827 in last 12 months.The highest frequency has occurred for the number of trades is three in last 12 months.

## Univariate Analysis on Demographic/application data

The demographic data there are 10 variables including the response variable, as we have seen earlier. According to the IV values we have selected some important variables(with IV values 0.3 to 0.5).From the exploratory analysis of demographic data following questions we will get the answer of following questions:
1.In which age group the maximum defaulters lies?
2.Does Marital status and Gender has any affect on the defaulterâ€™s behaviour?
3.Is No of dependents a significant contributor on defaulters?
4.Are type of Residence, Education and Profession a significant contributors?
5.Does residents month seems significant factor in the defaulting behaviour?

Now for further analysis let us explore this data set more as follows according to the name listed in data set:



***age***

```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(demogs$age)
library(ggplot2)
library(pander)
ggplot(demogs, aes(x = age)) +
  geom_histogram(binwidth = 2.50, color = "black",fill = "skyblue") +
  labs(
    x = "Age of customer",
    y = "Frequency",
    title = "Age Distribution of customer")
```

Maximum age of a customer is 65 where the median or middle age appeared is 45.The highest number of customer lies between age 40 to 55. From the summary statistics we also see that there is a customer with age -3.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
age_18_plus <- master[master$age >= 18, ] 

ggplot(age_18_plus, aes(age, fill = performance_tag)) + 
    geom_histogram(data = subset(age_18_plus,performance_tag==1),fill="red",alpha=.5) + 
    geom_histogram(data = subset(age_18_plus,performance_tag==0),fill="blue",alpha=.2) +
    ggtitle("Summary of outstanding_balance of a customer")
```

From the age distribution by performance we see that vary few customer are with performance tag 1 or bad customer. We can see that maximum defaulters in the age group 30-60.

***GENDER***

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# GENDER
ggplot(data = master) +
  geom_bar(mapping = aes(x = gender),fill = "blue",
        alpha = 0.4) +
  ggtitle("Summary of Gender")

# reshape the dataset
gender_by_perf <- master %>% group_by(gender,performance_tag) %>% summarise(count=n()) %>% drop_na()

# Stacked barplot using ggplot2
ggplot(gender_by_perf,                  
       aes(x = gender,
           y = count,
           fill = performance_tag)) +
  ggtitle("Performance Tag by Gender") +
  geom_bar(stat = "identity")
```

The count of Male customer is more than double of female customer.So, thus the case of bad male customer proportion is also higher than that of female with performance tag. Thus, we can say that gender of a customer also has some effects on their performance tag to be default or not.

***residence_months***

```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary(demogs$residence_months)

ggplot(master, aes(residence_months, fill = performance_tag)) + 
    geom_histogram(data = subset(master,performance_tag==1),fill="red",alpha=.5) + 
    geom_histogram(data = subset(master,performance_tag==0),fill="yellow",alpha=.4) +
  ggtitle("Performance Tag by residence_months")
```

This variable residence_months represents the number of months in current residence of customers, here we see that the default customer lives in the same residence for less than 10 months. The min number of months is 6 and maximum months in current resident is 126. 

***residence***

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(data = master) +
  geom_bar(mapping = aes(x = residence),fill = "green",
        alpha = 0.4) + ggtitle("Summary of residence of a customer")

# reshape the dataset
residence_by_perf <- master %>% group_by(residence,performance_tag) %>% summarise(count=n()) %>% drop_na()

# Stacked barplot using ggplot2
ggplot(residence_by_perf,                  
       aes(x = residence,
           y = count,
           fill = performance_tag)) +
  ggtitle("Performance Tag by type of residence of customers") +
  geom_bar(stat = "identity")
```

From the types of residence of customers distribution by performance tag, we see that the default customer residence types is rental as the number of customer with rental residence occurs most frequently.

***profession***

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#head(master)
ggplot(data = master) +
  geom_bar(mapping = aes(x = profession),fill = "red",
        alpha = 0.4) + ggtitle("Summary of profession of a customer")

# reshape the dataset
profession_by_perf <- master %>% group_by(profession,performance_tag) %>% summarise(count=n()) %>% drop_na()

# Stacked barplot 
ggplot(profession_by_perf,                  
       aes(x = profession,
           y = count,
           fill = performance_tag)) +
  ggtitle("Performance Tag by Profession") +
  geom_bar(stat = "identity")
```

In case of profession we also see that which profession highest frequency(SAL) has more performance tag than other professions. 

## Building model

As we know, the objective of model building is to know the relationship between the response variable and the independent variables.

##Demographic data model

Here, from the Demographic data model, we will get the answer of the question, what relationship residence_months, income, age, dependents, marital status, gender, company_months, education, residence or profession have on the customers performance.That is, to decide whether the customer will be a defaulter or not? 
Building different models like logistic regression with demographic and woe data will answer the question which factors will minimize the risk of probability of a customer being defaulter.In other words, which factors the bank manager need to focus more significantly.

## Summary of response variable

```{r, echo = FALSE, message=FALSE, warning=FALSE}
table(demogs$performance_tag)
prop.table(table(demogs$performance_tag))
```

Here, we see that 2948 customer is marked as 1 or default for performance  and 66922 customer is not default where as the proportion is 0.0422 and 0.9578 respectively.


***Logistic regression model building***

Logistic regression works for a data that contain continuous and/or categorical predictor variables. One advantage of logistic regression is that it computes a prediction probability score of an event.And, for predicting if a customer will default on a loan or not in Banking sector, binary classification or logistic regression is an effective method. Hence, it helps to identify and minimize the risk.

For fitting the logistic regression model we first spitted the data into two groups of train and test data, then using all the variables except customer ID from demographic dataset the logistic regression model has built as below:




```{r, echo = FALSE, message=FALSE, warning=FALSE}

demogs_drop_na <- demogs %>% drop_na(performance_tag)

set.seed(10)

#splitting
demogs_split <- initial_split(demogs_drop_na, prop = 0.70, strata=performance_tag)

demogs_train <- training(demogs_split)
demogs_test  <- testing(demogs_split)

#building model
logit_model <- glm(performance_tag ~ age+gender+marital+dependents+income+education+profession+residence+residence_months+company_months, data = demogs_train, family = "binomial")

#summary(logit_model1)



```

The logit models are now built.Comparing above models in terms of null and residual deviance, we find for that the logitmodel1 gives the best result. As, we know,the smaller the AIC, the better the model fits the data.Also, in comparison of null and residual deviance, this model gives best result.
We see that for all the model we get almost same predictions. So, we can say that the model accuracy of logistic regression classifier on test set is 95.88%. 



```{r, echo = FALSE, message=FALSE, warning=FALSE}

#prop.table(table(demogs_test$performance_tag))

#prediction
glm_predic_prob <- predict(logit_model, demogs_test, type = "response")

glm_predic_factor <- ifelse(glm_predic_prob > 0.05, 1, 0)

paste("accuracy is",100*mean(glm_predic_factor == demogs_test$performance_tag, na.rm = TRUE), "%")

demogs_test_glm <- demogs_test %>% bind_cols(.pred_factor=glm_predic_factor, .pred_prob=glm_predic_prob) %>%
  select(performance_tag, .pred_factor, .pred_prob) %>% drop_na()


bbbbbb <- demogs_test_glm %>%
select(performance_tag, .pred_factor)

bbbbbb[] <- lapply( bbbbbb, factor)

bbbbbb %>%
  conf_mat(truth = performance_tag, estimate = .pred_factor)
summary(bbbbbb)
#autoplot(bbbbbb, type = 'heatmap')

ROCit_obj <- rocit(score=demogs_test_glm$.pred_prob,class=demogs_test_glm$performance_tag)
plot(ROCit_obj)


```

## Bias Reduction in Generalized Linear Models (brglm)

```{r, echo = FALSE, message=FALSE, warning=FALSE}

 brglm_model  <- brglm(
   performance_tag~age+gender+marital+dependents+income+education+profession+residence+residence_months+company_months,
   
   family = binomial("probit"),
             data = demogs_train)
 
 #theta_brglm <- coef(brglm_model)
#summary(brglm_model)
#summary(fit1)
#exp(coef(fit1))
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
brglm_predic_prob <- predict(brglm_model, newdata = demogs_test, type = "response")
brglm_predic_factor <- ifelse(brglm_predic_prob > 0.05, 1, 0)
paste("accuracy is",100*mean(brglm_predic_factor == demogs_test$performance_tag, na.rm = TRUE),"%")

demogs_test_brglm <- demogs_test %>% bind_cols(.pred_factor=brglm_predic_factor, .pred_prob=brglm_predic_prob) %>%
  select(performance_tag, .pred_factor, .pred_prob) %>% drop_na()


ccccc <- demogs_test_brglm %>%
select(performance_tag, .pred_factor)

ccccc[] <- lapply( ccccc, factor)


ccccc %>% conf_mat(truth = performance_tag, estimate = .pred_factor) 
#summary(ccccc)


#ROCit_obj <- rocit(score=demogs_test_brglm$.pred_prob,class=demogs_test_brglm$performance_tag)
#plot(ROCit_obj)

```




0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111122222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333

## Model-building with WOE Demographic Data 

To compare with the logistic regression model with Demographic data, now we will build the same model with WOE Demographic data as below following the same procedure that we have done in case of demographic data:
```{r, echo = FALSE, message=FALSE, warning=FALSE}
library(tidymodels)
library(randomForest)
woe_demogs <- read_csv("woe_data.csv")
demogs %>%
na.omit(woe_demogs)
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
set.seed(123)
woe_demogs_split <- initial_split(woe_demogs, prop = 0.70, strata=performance_tag)
woe_demogs_train <- training(woe_demogs_split)
woe_demogs_test  <- testing(woe_demogs_split)  
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
woe_logit_model1 <- glm(performance_tag ~ residence_months+income+age+dependents+marital+gender+company_months+education+ residence+profession, data = woe_demogs_train, family = "binomial")
summary(woe_logit_model1)
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
woe_logit_predictions <- predict(woe_logit_model1, woe_demogs_test, type = "response")
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
y_pred_num_woe <- ifelse(woe_logit_predictions > 0.5, 1, 0)
y_pred_woe1 <- factor(y_pred_num_woe, levels=c(0, 1))
y_act <- woe_demogs_test$performance_tag
mean(y_pred_woe1 == y_act, na.rm = TRUE)

```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
woe_logit_model2 <- glm(performance_tag ~ residence_months+income+company_months+age+dependents, data = woe_demogs_train, family = "binomial")
summary(woe_logit_model2)
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
woe_logit_predictions2 <- predict(woe_logit_model2, woe_demogs_test, type = "response")
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
y_pred_num_woe <- ifelse(woe_logit_predictions2 > 0.5, 1, 0)
y_pred2 <- factor(y_pred_num_woe, levels=c(0, 1))
y_act <- demogs_test$performance_tag
mean(y_pred2 == y_act, na.rm = TRUE)

```
Here we also see that for both the model we get almost same predictions. So, we can say that the model accuracy of logistic regression classifier on test set is 96.13% which better than the demographic data model
accuracy. 

## cv for demogs
#Leave-One-Out Cross-Validation(loocv)
```{r , echo = FALSE, message=FALSE, warning=FALSE}
library(boot)
library(ISLR)
```

```{r , echo = FALSE, message=FALSE, warning=FALSE}
drop <- c("id")
demogs1 = demogs[,!(names(demogs) %in% drop)]
demogs1 <- head(demogs1, 1000)
demogs1
```

```{r , echo = FALSE, message=FALSE, warning=FALSE}
demogs1$performance_tag <- as.factor(demogs1$performance_tag)
demogs1$residence_months <- as.numeric(as.factor(demogs1$residence_months))
demogs1$income <- as.numeric(as.factor(demogs1$income))
demogs1$company_months <- as.numeric(as.factor(demogs1$company_months))
demogs1$age <- as.numeric(as.factor(demogs1$age))
demogs1$dependents <- as.numeric(as.factor(demogs1$dependents))
#head(demogs1)
glm.fit = glm(performance_tag ~ residence_months + income + company_months + 
    age + dependents, family = "binomial", data = demogs1)
cv.err = cv.glm(demogs1, glm.fit)

```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
cv.err$delta
```

```{r , echo = FALSE, message=FALSE, warning=FALSE}
cv.error = rep(0, 5)
for (i in 1:5) {
    glm.fit = glm(demogs1$performance_tag ~poly(demogs1$residence_months + demogs1$income + demogs1$company_months + 
    demogs1$age + demogs1$dependents, i), family = "binomial", data = demogs1)
    cv.error[i] = cv.glm(demogs1, glm.fit)$delta[1]
}
cv.error
```

## k-Fold Cross-Validation

```{r , echo = FALSE, message=FALSE, warning=FALSE}
set.seed(17)
cv.error.10 = rep(0, 10)
for (i in 1:10) {
    glm.fit = glm(demogs1$performance_tag ~poly(demogs1$residence_months + demogs1$income + demogs1$company_months + 
    demogs1$age + demogs1$dependents, i),family = "binomial", data = demogs1)
    cv.error.10[i] = cv.glm(demogs1, glm.fit, K = 10)$delta[1]
}
cv.error.10
```
Here,from our cross-validation we see that the test error is approximately 0.002 for the estimates used in the model and the numbers are almost identical for the errors. So, we can say that,the error is minimized in this case compared to the logistic regression model.

## random forest with demograghic data

```{r, echo = FALSE, message=FALSE, warning=FALSE}
set.seed(1234)
demogs_split <- initial_split(demogs, prop = 0.70, strata=performance_tag)
demogs_train <- training(demogs_split)
demogs_test  <- testing(demogs_split)
#head(demogs_test)
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
demogs_train$performance_tag <- ifelse(demogs_train$performance_tag == "yes", 1, 0)
demogs_train$performance_tag <- factor(demogs_train$performance_tag, levels = c(0, 1))
#head(demogs_train)
```

```{r , echo = FALSE, message=FALSE, warning=FALSE}
library(tidymodels)
library(vip)

# Specify a random forest
spec <- rand_forest(mtry = 10, trees = 5000, min_n = 10) %>%
	set_mode("classification") %>%
    set_engine("ranger", importance = "impurity")

# Train the forest
model <- spec %>%
    fit(performance_tag ~ age+gender+marital+dependents+income+education+profession+residence+residence_months+company_months, data = demogs_train)
model
```


```{r , echo = FALSE, message=FALSE, warning=FALSE}

demogs_test <- na.omit(demogs_test) 
demogs_test$performance_tag <- ifelse(demogs_test$performance_tag == "yes", 1, 0)
demogs_test$performance_tag <- factor(demogs_test$performance_tag, levels = c(0, 1))
demogs_test$residence_months <- as.numeric(as.factor(demogs_test$residence_months))
demogs_test$income <- as.numeric(as.factor(demogs_test$income))
demogs_test$company_months <- as.numeric(as.factor(demogs_test$company_months))
demogs_test$age <- as.numeric(as.factor(demogs_test$age))
demogs_test$dependents <- as.numeric(as.factor(demogs_test$dependents))
predictions <- predict(model, new_data = demogs_test) %>%
  bind_cols(demogs_test) 
predictions
```


```{r , echo = FALSE, message=FALSE, warning=FALSE}
conf_mat(predictions,
     estimate = .pred_class,
     truth = performance_tag)
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
accuracy(predictions,
     estimate = .pred_class,
     truth = performance_tag)
```


0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000011111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111122222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222223333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333


## building a new dataset with determinant variables

```{r, echo = FALSE, message=FALSE, warning=FALSE}

# selecting important predictors
woe_data_selected <- woe_data %>%
  select(
         # these 15 variables from demogs dataset
    
         inquiries_12m,
         utilization_12m,
         pl_trades_12m,
         trades_opened_12m,
         outstanding_balance,
         total_no_of_trades,
         dpd_30_6m,
         pl_trades_6m,
         dpd_90_12m,
         inquiries_6m,
         dpd_60_6m,
         dpd_30_12m,
         trades_6m,
         dpd_60_12m,
         dpd_90_6m,
         
         # these 3 variables from demogs dataset
         
         residence_months,
         income,
         company_months,
         
         # response variable
         
         performance_tag) %>%
  na.omit(performance_tag)


```

## Split the data

```{r, echo = FALSE, message=FALSE, warning=FALSE}
set.seed(10)

training.samples <- woe_data_selected$performance_tag %>%
  createDataPartition(p = 0.6, list = FALSE)

train.data  <- woe_data_selected[training.samples, ]
test.data <- woe_data_selected[-training.samples, ]

#train.data %>% group_by(performance_tag) %>% count()

print(prop.table(table(train.data$performance_tag)))

```
## Support Vector Machines

***SVM linear classifier***

```{r, echo = FALSE, message=FALSE, warning=FALSE}

# Fit the model on the training set
set.seed(123)
model <- train(
  as.factor(performance_tag) ~., data = train.data, method = "svmLinear",
  trControl = trainControl("cv", number = 10),
  preProcess = c("center","scale")
  )


```

*** Make predictions on the test data***

```{r, echo = FALSE, message=FALSE, warning=FALSE}
predicted.classes <- model %>% predict(test.data)
head(predicted.classes)
```

***binding predictions and truth ***

```{r, echo = FALSE, message=FALSE, warning=FALSE}


data_bind <- test.data %>%
   bind_cols(.pred=predicted.classes)


test_pred_mat <- data_bind %>% conf_mat(truth = performance_tag, estimate = .pred)
summary(test_pred_mat)
autoplot(test_pred_mat, type = 'heatmap')
```

## Undersampling

```{r, echo = FALSE, message=FALSE, warning=FALSE}


master_WOE_train_balanced <- ovun.sample(performance_tag ~ ., data = train.data, method = "under",N = 4700)$data

master_WOE_train_balanced %>%
  group_by(performance_tag) %>%
  count()





```

## SVM linear classifier

```{r, echo = FALSE, message=FALSE, warning=FALSE}

# Fit the model on the training set
set.seed(123)



model2 <- train(
  as.factor(performance_tag) ~., data = master_WOE_train_balanced, method = "svmLinear",
  trControl = trainControl("cv", number = 50),
  preProcess = c("center","scale")
  )

# Make predictions on the test data

predicted.classes2 <- model2 %>% predict(test.data)
head(predicted.classes2)

# binding predictions and truth 

data_bind2 <- test.data %>%
   bind_cols(.pred=predicted.classes2)




```


```{r, echo = FALSE, message=FALSE, warning=FALSE}
test_pred_mat2 <- data_bind2 %>% conf_mat(truth = performance_tag, estimate = .pred)
summary(test_pred_mat2)
autoplot(test_pred_mat2, type = 'heatmap')



```

